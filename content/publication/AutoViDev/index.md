+++
title = "AutoViDev: A computer-vision framework to enhance and accelerate research in human development"
date = 2019-05-01T00:00:00
draft = false

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Ori Ossmy", "Rick O. Gilmore", "Karen E. Adolph"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["1"]

# Publication name and optional abbreviated version.
publication = "In *Computer Vision Conference (CVC) 2019*"
publication_short = "In *CVC 2019*"

# Abstract and optional shortened version.
abstract = "Interdisciplinary exchange of ideas and tools can accelerate scientific progress. For example, findings from developmental and vision science have spurred recent advances in artificial intelligence and computer vision. However, relatively little attention has been paid to how artificial intelligence and computer vision can facilitate research in developmental science. The current study presents AutoViDev—an automatic video-analysis tool that uses machine learning and computer vision to support video-based developmental research. AutoViDev identifies full body position estimations in real-time video streams using convolutional pose machine-learning algorithms. AutoViDev provides valuable information about a variety of behaviors, including gaze direction, facial expressions, posture, locomotion, manual actions, and interactions with objects. We present a high-level architecture of the framework and describe two projects that demonstrate its usability. We discuss the benefits of applying AutoViDev to large-scale, shared video datasets and highlight how machine learning and computer vision can enhance and accelerate research in developmental science."
# abstract_short = ""

# Is this a selected publication? (true/false)
selected = true

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["AI", "computer vision", "data science", "video", "Databrary"]

# Links (optional).
# url_pdf = "https://eprints.soton.ac.uk/352095/1/Cushen-IMV2013.pdf"
# url_preprint = "https://eprints.soton.ac.uk/352095/1/Cushen-IMV2013.pdf"
# url_code = "#"
# url_dataset = "#"
# url_project = ""
# url_slides = "#"
# url_video = "#"
# url_poster = "#"
# url_source = "#"

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "https://example.org"}]

# Digital Object Identifier (DOI)
doi = "https://doi.org/10.1007%2F978-3-030-17798-0_14"

# Does this page contain LaTeX math? (true/false)
math = true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]
  # Caption (optional)
  caption = "Using AutoViDev offline mode for automatic detection of infant locomotion. (a) Researchers manually track infants in a video (left) to determine their path over 20 minutes of free-play. Figure on the right depicts one 20-minute path that was manually extracted. (b) AutoViDev can achieve similar tracking by detecting the infant’s feet and generating the 20-minute path. The AutoViDev tracked path significantly matched the manually digitized path."

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = ""
+++
